# Phase 4: Scale-out 적용 (10개 인스턴스)

## 목적

- **애플리케이션 Scale-out**을 통한 처리량 향상
- Phase 3 (단일 인스턴스)와 비교하여 Scale-out의 효과 확인
- 연결 풀 경합 문제 파악

---

## 준비 작업

### 애플리케이션 Scale-out 설정

`docker-compose.yml`에서 애플리케이션 인스턴스 수를 10개로 설정:

```yaml
app:
  image: eclipse-temurin:21-jre
  deploy:
    replicas: 10
  # ... 기타 설정
```

**실행 체크리스트**:

- [ ] `docker-compose.yml` 파일에서 `app` 서비스의 `replicas` 설정 확인 (10개)
- [ ] Docker Swarm 스택 배포
- [ ] 10개 인스턴스가 정상적으로 실행되는지 확인
- [ ] 애플리케이션이 정상적으로 작동하는지 확인

---

## 설정 정보

### 애플리케이션 인스턴스

- **인스턴스 수**: 10개
- **인스턴스당 메모리**: 최대 1GB, 예약 512MB
- **연결 풀 설정**: HikariCP `maximum-pool-size=50` (인스턴스당)

### 데이터베이스 연결

- **PostgreSQL 최대 연결 수**: 500개
- **이론적 최대 연결 수**: 10개 인스턴스 × 50개 = 500개
- **연결 풀 경합 가능성**: 높음 (500/500 정확히 한계치)

---

## k6 실행

**Phase 3와 동일한 시나리오 사용**:

```bash
cd k6-tests
k6 run --out json=results/results-scale_out_no_pgbouncer.json scenario-phase1.js
```

**참고**: Phase 3와 동일한 데이터셋(`step1-dataset.json`)과 동일한 시나리오를 사용하여 공정한 비교가 가능합니다.

**실행 체크리스트**:

- [ ] `k6-tests/test-data/step1-dataset.json` 파일 존재 확인
- [ ] Phase 3와 동일한 k6 시나리오 사용
- [ ] k6 테스트 실행
- [ ] 결과 파일 확인 (`results/results-scale_out_no_pgbouncer.json`)

---

## 결과 기록

### 성능 지표 요약

| 지표                   | Phase 3 (단일 인스턴스) | Phase 4 (Scale-out) | 개선율 (3→4) |
| ---------------------- | ----------------------- | ------------------- | ------------ |
| **응답 시간**          |
| p50 latency            | 258 ms                  | 744 ms              | +188% 악화   |
| p95 latency            | 10,714 ms               | 4,431 ms            | -58.6% 개선  |
| **처리량**             |
| RPS                    | 100.5 req/s             | 712.4 req/s         | +609% 증가   |
| 요청 실패율            | 1.22%                   | 2.02%               | +65.6% 악화  |
| **연결 관련**          |
| http_req_blocked p(95) | 7,686 ms                | 911 ms              | -88.1% 개선  |
| **리디렉션 지연**      |
| redirect_latency p(95) | 154,583 ms              | 9,239 ms            | -94.0% 개선  |

**참고**:

- 전체 요청 시간(`http_req_duration`)은 네트워크 지연을 포함합니다.
- Scale-out으로 인해 전체 처리량은 크게 증가했으나, 연결 풀 경합으로 인한 문제가 발생했습니다.

### Scale-out 효과

**주요 개선**:

- **처리량**: 100.5 req/s → 712.4 req/s (+609% 증가) - 가장 큰 개선
- **p95 응답 시간**: 10.7초 → 4.4초 (-58.6% 개선)
- **리디렉션 지연 p(95)**: 154.6초 → 9.2초 (-94.0% 개선)
- **연결 블로킹 시간 p(95)**: 7.7초 → 0.9초 (-88.1% 개선)

**문제점**:

- **요청 실패율**: 1.22% → 2.02% (+65.6% 악화)
- **p50 응답 시간**: 258 ms → 744 ms (+188% 악화)
- **연결 풀 경합**: 10개 인스턴스 × 50개 연결 풀 = 500개 (PostgreSQL 최대 연결 수와 일치)

### 연결 풀 경합 분석

**설정 분석**:

- **애플리케이션 인스턴스**: 10개
- **인스턴스당 연결 풀**: 50개 (HikariCP)
- **총 연결 풀 크기**: 500개
- **PostgreSQL 최대 연결 수**: 500개

**결론**:

연결 풀 크기가 PostgreSQL의 최대 연결 수와 정확히 일치하여 연결 풀 경합이 발생했습니다. 이로 인해:

- 새로운 연결을 얻기 위해 대기하는 시간 증가
- 일부 요청의 응답 시간 증가
- 요청 실패율 증가

---

## 상세 분석

### k6 테스트 결과 요약

- **총 요청 수**: 514,557건
- **요청 처리율**: 712.4 req/s
- **요청 실패율**: 2.02% (threshold: <1%, 미달)
- **테스트 시간**: ~12.0분

### 성능 메트릭 상세

**전체 요청 시간 (http_req_duration)**:

- p50: 744ms
- p95: 4,431ms
- 평균: 1,284ms
- 최대: 27.5초

**리디렉션 지연 (redirect_latency)**:

- p50: 2,621ms
- p95: 9,239ms
- 평균: 3,397ms
- 최대: 33.7초

**연결 블로킹 시간 (http_req_blocked)**:

- p50: 0ms
- p95: 911ms
- 평균: 148ms
- 최대: 18.4초

**연결 시간 (http_req_connecting)**:

- p50: 0ms
- p95: 450ms
- 평균: 107ms
- 최대: 15.6초

---

## 산출물

- **k6 결과**: `results-scale_out_no_pgbouncer.json`
- **성능 개선표**: 위 표 작성 완료

---

## 다음 단계

Phase 4 완료 후 → [Phase 5: PgBouncer 적용](./phase5-pgbouncer.md) 진행
